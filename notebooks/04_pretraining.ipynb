{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "9oIRgwWm0J5x"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "bbig_vjZsHbf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DummyGPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "    )\n",
        "\n",
        "    self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(\n",
        "        torch.arange(seq_len, device=in_idx.device)\n",
        "    )\n",
        "\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "\n",
        "    return logits\n",
        "\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "class DummyLayerNorm(nn.Module):\n",
        "  def __init__(self, normalized_shape, eps=1e-5):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmDudPAMtISb"
      },
      "source": [
        "```python\n",
        "in_idx = [[1, 2, 1032, 2023],\n",
        "          [5, 920, 192, 1023]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJxkQvNxuhbI",
        "outputId": "250651c4-3784-4f81-8e22-0806acc7d8e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "batch = []\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM9mCfAJ39Xo",
        "outputId": "cf1e98a0-0c71-4746-b5dc-7009cf9a80fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 4, 50257])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "logits = model(batch)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JzUf6FF94HwK",
        "outputId": "89c4790a-893d-42ee-b893-ca401ee65443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
            "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
            "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
            "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
            "\n",
            "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
            "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
            "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
            "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aZfCgGz4U1-"
      },
      "source": [
        "#**2. LayerNorm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urMTtmU6wsmV",
        "outputId": "c682f768-6430-4c69-8dad-e6e978dedac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "batch_example = torch.randn(2, 5)\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch_example)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibjgqpee4zBA",
        "outputId": "b301197c-438d-460c-a5e2-a7618bb7a92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1324],\n",
            "        [0.2170]], grad_fn=<MeanBackward1>)\n",
            "tensor([[0.0231],\n",
            "        [0.0398]], grad_fn=<VarBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "var = out.var(dim=-1, keepdim=True)\n",
        "\n",
        "print(mean), print(var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N73u5SpF5DV9",
        "outputId": "1fcb0a04-52f3-4788-8042-b807417c9aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
            "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "tensor([[-0.0000],\n",
            "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
            "tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_norm = (out - mean) / torch.sqrt(var)\n",
        "\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "\n",
        "print(out_norm), print(mean), print(var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k38wGWKU5ru0",
        "outputId": "15779a18-d655-4e80-e4ec-8e2317a23995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.0000],\n",
            "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
            "tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "print(mean), print(var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "aRLOoJQl5zmJ"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "    self.eps = 1e-5\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    norm_x = (x - mean) / (var + self.eps)**0.5\n",
        "\n",
        "    return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4bidzJh6eBe",
        "outputId": "5b9dae77-8471-4a43-8a6d-bac41e534439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean:\n",
            " tensor([[-0.0000],\n",
            "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ],
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "out_ln = ln(batch_example)\n",
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "7ZFwuTF86ud7"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "        (x + 0.044715 * torch.pow(x, 3))\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "DdHnAzFqUGKp",
        "outputId": "f3337f8a-ca2f-4b58-9bfd-a206fbde49f0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "plt.figure(figsize=(8, 3))\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "  plt.subplot(1, 2, i)\n",
        "  plt.plot(x, y)\n",
        "  plt.title(f\"{label} activation function\")\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.ylabel(f\"{label}(x)\")\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "v5Bku4d1UP4O"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-HwgZ7QUor0",
        "outputId": "13e7b9fd-4ca5-449e-bd09-8debd38fe051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ],
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "x = torch.rand(2, 3, 768)\n",
        "out = ffn(x)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "CMRPjRXTUx9i"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "\n",
        "    assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
        "\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    self.out_proj = nn.Linear(d_out, d_out)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(\n",
        "        b, num_tokens, self.num_heads, self.head_dim\n",
        "    )\n",
        "\n",
        "    keys = keys.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2, 3)\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "    attn_scores.masked_fill(mask_bool, -torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "    )\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "    context_vec = context_vec.contiguous().view(\n",
        "        b, num_tokens, self.d_out\n",
        "    )\n",
        "\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "\n",
        "    return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "p5PZH-n3Wig8"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "\n",
        "    self.att = MultiHeadAttention(\n",
        "        d_in=cfg[\"emb_dim\"],\n",
        "        d_out=cfg[\"emb_dim\"],\n",
        "        context_length=cfg[\"context_length\"],\n",
        "        num_heads=cfg[\"n_heads\"],\n",
        "        dropout=cfg[\"drop_rate\"],\n",
        "        qkv_bias=cfg[\"qkv_bias\"]\n",
        "    )\n",
        "\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O9A3K49WpDq",
        "outputId": "9533afe0-3aa6-4a70-8c6f-998e9adae246"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 4, 768]), torch.Size([2, 4, 768]))"
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "x = torch.rand(2, 4, 768)\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(x)\n",
        "\n",
        "x.shape, output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "CPusPcnXXVJZ"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "      *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "    )\n",
        "\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "      cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(\n",
        "      torch.arange(seq_len, device=in_idx.device)\n",
        "    )\n",
        "\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWhUh4TKYjAD",
        "outputId": "b2be58a0-589b-42bc-f323-6a19f033df70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input batch:\n",
            " tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n",
            "\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[ 0.4167, -0.0676, -0.2001,  ...,  0.3916,  0.1081, -0.1607],\n",
            "         [ 0.3593, -0.6993, -0.8715,  ..., -0.2451,  0.2673, -0.2367],\n",
            "         [ 1.0220,  0.0540, -0.3235,  ...,  0.0761, -0.5456, -0.1451],\n",
            "         [-0.8916,  0.4795, -0.2215,  ...,  0.6458,  0.3718,  0.1394]],\n",
            "\n",
            "        [[-0.4959, -0.2750, -0.0627,  ...,  0.2587,  0.1351, -0.3289],\n",
            "         [ 0.2549,  0.3801, -0.1802,  ...,  0.6806, -0.0931,  0.4824],\n",
            "         [ 1.1538,  0.7210, -0.2097,  ...,  0.8688,  0.1912, -0.2601],\n",
            "         [-0.0953,  0.5321,  0.2437,  ...,  1.2450, -0.1883, -0.0224]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "out = model(batch)\n",
        "\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_yjhMytYpet",
        "outputId": "829989bc-4765-4789-fc9f-917a0b055eaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163,009,536\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8-jPknBY1u0",
        "outputId": "9d5e8ae0-83ba-4bfc-ec62-eddb88959494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ],
      "source": [
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzcNiYwHZFzg",
        "outputId": "f2c403a6-c6d8-462f-b3f0-ecbd21203946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters considering weight tying: 124,412,160\n"
          ]
        }
      ],
      "source": [
        "total_params_gpt2 = (\n",
        "    total_params - sum(p.numel()\n",
        "    for p in model.out_head.parameters())\n",
        "  )\n",
        "\n",
        "print(f\"Number of trainable parameters \"\n",
        "f\"considering weight tying: {total_params_gpt2:,}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXv8gBAeZPAx",
        "outputId": "a30e5635-56cd-471d-b829-172d77f81f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total size of the model: 621.83 MB\n"
          ]
        }
      ],
      "source": [
        "total_size_bytes = total_params * 4\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "o97Y7nbPZUyJ"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XM5uXYJZ8ex",
        "outputId": "ad178a0c-b488-4718-95ad-c0fe1fde2168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HInJSa-HaAdW",
        "outputId": "09c616c3-756e-4247-fe86-21eb2ec53b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[15496,    11,   314,   716, 27018,  7283, 46275, 41426, 33167, 33239]])\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "out = generate_text_simple(model=model, idx=encoded_tensor, max_new_tokens=6, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
        "print(out)\n",
        "print(len(out[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH1UpCPzaPY7",
        "outputId": "1cbc03f9-6062-4eaf-d879-ea5d66f3d9d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, I am Feature IT snowballProtect youngstersMu\n"
          ]
        }
      ],
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTDZcy_YMIFV"
      },
      "source": [
        "# **next chapter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qFij0WMaMFIy",
        "outputId": "b7360d46-f1ed-4449-a483-d52a0db17727"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 274,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "  \"vocab_size\": 50257,\n",
        "  \"context_length\": 256,\n",
        "  \"emb_dim\": 768,\n",
        "  \"n_heads\": 12,\n",
        "  \"n_layers\": 12,\n",
        "  \"drop_rate\": 0.1,\n",
        "  \"qkv_bias\": False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "LP1H0b3IMK8n"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqnhMg6mMqNc",
        "outputId": "2acf55b4-f4df-40ac-bf72-24ce59301866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic minion mobilized Macicone warrantyuler respirmediated\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "4u3Qvwa6NBnL"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
        "                        [40, 1107, 588]])   # \"I really like\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "LtV94VBUNQzb"
      },
      "outputs": [],
      "source": [
        "targets = torch.tensor([[3626, 6100, 345 ],  # [\" effort moves you\",\n",
        "                        [1107, 588, 11311]]) # \" really like chocolate\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3pJo0L_NW3K",
        "outputId": "89f06320-96b1-4f38-fd14-77a32c1cfce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "probas = torch.softmax(logits, dim=-1)\n",
        "print(probas.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LgWF-R9NgLw",
        "outputId": "3f51dd81-32a1-4d10-fa75-5e895c55653d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token IDs:\n",
            " tensor([[[36195],\n",
            "         [16031],\n",
            "         [42826]],\n",
            "\n",
            "        [[14212],\n",
            "         [ 7822],\n",
            "         [38509]]])\n"
          ]
        }
      ],
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWx_YHnWNmr5",
        "outputId": "c4bbfdfc-802c-4722-eb69-739e1a796a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1: lif savesNetflix\n"
          ]
        }
      ],
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1:\"\n",
        "f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjXfsePdNrPq",
        "outputId": "adfdf03d-a9af-407d-bd27-0e3aaf167a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text 1: tensor([0.0000, 0.0000, 0.0000])\n",
            "Text 2: tensor([0.0000, 0.0000, 0.0000])\n"
          ]
        }
      ],
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRKDCDxnOB-Z",
        "outputId": "482d109b-1be6-4579-b9c3-d57c5423f484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-10.0934, -10.8504, -11.3984, -11.3410, -10.0880, -12.1543])\n"
          ]
        }
      ],
      "source": [
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zeA6CSIOGZk",
        "outputId": "721c944e-5f9a-4ff6-cc1a-fb2f4566a9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(-10.9876)\n"
          ]
        }
      ],
      "source": [
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAfKKM8EOK_c",
        "outputId": "315de2eb-3ec5-4f18-d37d-bc14ec8231be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.9876)\n"
          ]
        }
      ],
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiFr-KQ4OO3Y",
        "outputId": "bff33b70-34e2-48b8-d3c9-0fd348930b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(\"Logits shape:\", logits.shape)\n",
        "print(\"Targets shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gne6WGgOS4Y",
        "outputId": "05d66a2e-d458-4e4b-9016-7a19d9c44c0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([6, 50257]), torch.Size([6]))"
            ]
          },
          "execution_count": 287,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "logits_flat.shape, targets_flat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JorzW3MyOZTD",
        "outputId": "9eabd66a-c8bc-46a3-82cf-e5c9419aeb8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.9876)\n"
          ]
        }
      ],
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQk0BInePdZ7",
        "outputId": "5870689c-c8ef-4be1-ed48-26ef02552c7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x1358bb150>)"
            ]
          },
          "execution_count": 289,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# downloading the text file (the verdict)\n",
        "import urllib.request\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "Eg_kYHozOjjo"
      },
      "outputs": [],
      "source": [
        "file_path = \"the-verdict.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  text_data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XsPDsmPPSrG",
        "outputId": "14498422-2dab-469b-fba5-f695f815151f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "Gy2gNfdOP2D8"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "SxzK06VIP6wA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i: i + max_length]\n",
        "      target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "TTv28BCBQCf6"
      },
      "outputs": [],
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "\n",
        "  return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "Qey5LJeUQDgp"
      },
      "outputs": [],
      "source": [
        "train_loader = create_dataloader_v1(\n",
        "train_data,\n",
        "batch_size=2,\n",
        "max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "drop_last=True,\n",
        "shuffle=True,\n",
        "num_workers=0\n",
        ")\n",
        "val_loader = create_dataloader_v1(\n",
        "val_data,\n",
        "batch_size=2,\n",
        "max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "drop_last=False,\n",
        "shuffle=False,\n",
        "num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9ruOpBQQFil",
        "outputId": "8357768a-9fdf-4768-eb44-03794aa62e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "  print(x.shape, y.shape)\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "  print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "eiF0NsE0QHcW"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(\n",
        "  logits.flatten(0, 1), target_batch.flatten()\n",
        "  )\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "GywErs8DQMAX"
      },
      "outputs": [],
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(\n",
        "        input_batch, target_batch, model, device\n",
        "      )\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6LaIlw9QXc-",
        "outputId": "8b289a76-fd3e-4d93-cd7a-eba3f46049fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using mps\n",
            "Training loss: 10.987583054436577\n",
            "Validation loss: 10.982393264770508\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device}\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "id": "Mv1jcjlpQ8ut"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(\n",
        "    train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "    val_loss = calc_loss_loader(\n",
        "    val_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "id": "6HmNYcvPRAwQ"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(\n",
        "    model=model, idx=encoded,\n",
        "    max_new_tokens=50, context_size=context_size\n",
        "    )\n",
        "  decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\", \" \"))\n",
        "  model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "id": "xSOlf9T5Qa1p"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader,\n",
        "                        optimizer, device, num_epochs,\n",
        "                        eval_freq, eval_iter, start_context, tokenizer):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(\n",
        "      input_batch, target_batch, model, device\n",
        "      )\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(\n",
        "        model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "            f\"Train loss {train_loss:.3f}, \"\n",
        "            f\"Val loss {val_loss:.3f}\"\n",
        "        )\n",
        "    generate_and_print_sample(model, tokenizer, device, start_context)\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDSK-QClRInU",
        "outputId": "7705026b-a9ad-4770-ae50-d6bacc7e2e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 10.829, Val loss 10.812\n",
            "Ep 1 (Step 000005): Train loss 9.549, Val loss 9.627\n",
            "Every effort moves you was-- was-- wasI was-- was-- wasIII was------ was-- was--I was-- was---- was-- was was was-- was-- was-- was-- wasI was---- wasI was-- was\n",
            "Ep 2 (Step 000010): Train loss 8.349, Val loss 8.547\n",
            "Ep 2 (Step 000015): Train loss 7.488, Val loss 7.719\n",
            "Every effort moves you----------------------------------------------------------------------------------------------------\n",
            "Ep 3 (Step 000020): Train loss 6.630, Val loss 6.962\n",
            "Ep 3 (Step 000025): Train loss 6.190, Val loss 6.676\n",
            "Every effort moves you..................................................\n",
            "Ep 4 (Step 000030): Train loss 6.080, Val loss 6.663\n",
            "Ep 4 (Step 000035): Train loss 6.079, Val loss 6.721\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Ep 5 (Step 000040): Train loss 6.006, Val loss 6.733\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Ep 6 (Step 000045): Train loss 6.029, Val loss 6.715\n",
            "Ep 6 (Step 000050): Train loss 6.045, Val loss 6.712\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Ep 7 (Step 000055): Train loss 6.071, Val loss 6.720\n",
            "Ep 7 (Step 000060): Train loss 6.021, Val loss 6.717\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Ep 8 (Step 000065): Train loss 5.981, Val loss 6.700\n",
            "Ep 8 (Step 000070): Train loss 6.045, Val loss 6.692\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Ep 9 (Step 000075): Train loss 6.038, Val loss 6.681\n",
            "Ep 9 (Step 000080): Train loss 6.046, Val loss 6.677\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Ep 10 (Step 000085): Train loss 5.991, Val loss 6.671\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[303]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m optimizer = torch.optim.AdamW(\n\u001b[32m      5\u001b[39m   model.parameters(),\n\u001b[32m      6\u001b[39m   lr=\u001b[32m0.0004\u001b[39m, weight_decay=\u001b[32m0.1\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m num_epochs = \u001b[32m25\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m train_losses, val_losses, tokens_seen = \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m  \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m  \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvery effort moves you\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[302]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_model_simple\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m input_batch, target_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m      9\u001b[39m   optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m   loss = \u001b[43mcalc_loss_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m  \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m   loss.backward()\n\u001b[32m     14\u001b[39m   optimizer.step()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[297]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcalc_loss_batch\u001b[39m\u001b[34m(input_batch, target_batch, model, device)\u001b[39m\n\u001b[32m      2\u001b[39m input_batch = input_batch.to(device)\n\u001b[32m      3\u001b[39m target_batch = target_batch.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m loss = torch.nn.functional.cross_entropy(\n\u001b[32m      6\u001b[39m logits.flatten(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m), target_batch.flatten()\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[264]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mGPTModel.forward\u001b[39m\u001b[34m(self, in_idx)\u001b[39m\n\u001b[32m     25\u001b[39m x = tok_embeds + pos_embeds\n\u001b[32m     26\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_emb(x)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrf_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_norm(x)\n\u001b[32m     29\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.out_head(x)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[262]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     21\u001b[39m shortcut = x\n\u001b[32m     22\u001b[39m x = \u001b[38;5;28mself\u001b[39m.norm1(x)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43matt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_shortcut(x)\n\u001b[32m     25\u001b[39m x = x + shortcut\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[261]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     43\u001b[39m attn_weights = torch.softmax(\n\u001b[32m     44\u001b[39m     attn_scores / keys.shape[-\u001b[32m1\u001b[39m]**\u001b[32m0.5\u001b[39m, dim=-\u001b[32m1\u001b[39m\n\u001b[32m     45\u001b[39m )\n\u001b[32m     46\u001b[39m attn_weights = \u001b[38;5;28mself\u001b[39m.dropout(attn_weights)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m context_vec = \u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m context_vec = context_vec.contiguous().view(\n\u001b[32m     51\u001b[39m     b, num_tokens, \u001b[38;5;28mself\u001b[39m.d_out\n\u001b[32m     52\u001b[39m )\n\u001b[32m     54\u001b[39m context_vec = \u001b[38;5;28mself\u001b[39m.out_proj(context_vec)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "  model.parameters(),\n",
        "  lr=0.0004, weight_decay=0.1\n",
        ")\n",
        "num_epochs = 10\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "  model, train_loader, val_loader, optimizer, device,\n",
        "  num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "  start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "wqV0MYKERQk3",
        "outputId": "a76e7bd0-0451-4aaf-bcb5-e803687b6196"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "  ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "  ax1.plot(\n",
        "  epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
        "  )\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "  ax2.set_xlabel(\"Tokens seen\")\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js_VYWJPTYBW",
        "outputId": "134c784d-cb5a-49c0-ffdc-c449837bc912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR4HJLYWFS2A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.4)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
