{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921902de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from modules import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "  \"vocab_size\": 50257,\n",
    "  \"context_length\": 256,\n",
    "  \"emb_dim\": 768,\n",
    "  \"n_heads\": 12,\n",
    "  \"n_layers\": 12,\n",
    "  \"drop_rate\": 0.1,\n",
    "  \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2ee444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "  return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "  flat = token_ids.squeeze(0)\n",
    "  return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b43fe178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modules' from '/Users/vedantmisra/Developer/llm-from-scratch/notebooks/modules.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import modules\n",
    "importlib.reload(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e6c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic minion mobilized Macicone warrantyuler respirmediated\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from modules import generate_text_simple\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5e9d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                        [40, 1107, 588]])   # \"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb1bb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345 ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]]) # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b76fb617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1230276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[36195],\n",
      "         [16031],\n",
      "         [42826]],\n",
      "\n",
      "        [[14212],\n",
      "         [ 7822],\n",
      "         [38509]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "436e07de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: lif savesNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d47d097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([4.1353e-05, 1.9397e-05, 1.1213e-05])\n",
      "Text 2: tensor([1.1875e-05, 4.1576e-05, 5.2655e-06])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=True)\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fe192c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.0934, -10.8504, -11.3984, -11.3410, -10.0880, -12.1543])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43f2a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.9876)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2897668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9876)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f8a2dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "917c1bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "967fe091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9876)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9658c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5043ce37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "801dbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac39e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b704ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3fd9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0491bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cd5562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "model.to(device)\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11cfe847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583372328016\n",
      "Validation loss: 10.982393264770508\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  train_loss = calc_loss_loader(train_loader, model, device)\n",
    "  val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "490c3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "    train_loader, model, device, num_batches=eval_iter\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "    val_loader, model, device, num_batches=eval_iter\n",
    "    )\n",
    "  model.train()\n",
    "  return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83986146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "  model.eval()\n",
    "  context_size = model.pos_emb.weight.shape[0]\n",
    "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "  with torch.no_grad():\n",
    "    token_ids = generate_text_simple(\n",
    "    model=model, idx=encoded,\n",
    "    max_new_tokens=50, context_size=context_size\n",
    "    )\n",
    "  decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "  print(decoded_text.replace(\"\\n\", \" \"))\n",
    "  model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5755b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                        optimizer, device, num_epochs,\n",
    "                        eval_freq, eval_iter, start_context, tokenizer):\n",
    "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "  tokens_seen, global_step = 0, -1\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for input_batch, target_batch in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "      loss = calc_loss_batch(\n",
    "      input_batch, target_batch, model, device\n",
    "      )\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      tokens_seen += input_batch.numel()\n",
    "      global_step += 1\n",
    "      if global_step % eval_freq == 0:\n",
    "        train_loss, val_loss = evaluate_model(\n",
    "        model, train_loader, val_loader, device, eval_iter)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        track_tokens_seen.append(tokens_seen)\n",
    "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "            f\"Train loss {train_loss:.3f}, \"\n",
    "            f\"Val loss {val_loss:.3f}\"\n",
    "        )\n",
    "    generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "  return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8587524f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.962, Val loss 10.061\n",
      "Ep 1 (Step 000005): Train loss 8.211, Val loss 8.456\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000010): Train loss 6.654, Val loss 7.079\n",
      "Ep 2 (Step 000015): Train loss 6.067, Val loss 6.605\n",
      "Every effort moves you, the,, the,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.626, Val loss 6.464\n",
      "Ep 3 (Step 000025): Train loss 5.609, Val loss 6.432\n",
      "Every effort moves you, and, and, and, and, and, and, and, and,, and,,,, and, and, and, and,, and, and,, and, and, and, and,,, and,,\n",
      "Ep 4 (Step 000030): Train loss 5.213, Val loss 6.320\n",
      "Ep 4 (Step 000035): Train loss 5.003, Val loss 6.407\n",
      "Every effort moves you know; and my painting. The. The to the picture. Gisburn. Gisburn, and! The. Gisburn. I had been a Jackisburn. Gisburn, and a a lump of the picture. The\n",
      "Ep 5 (Step 000040): Train loss 4.552, Val loss 6.281\n",
      "Every effort moves you know it's his pictures--I had been to the picture.                                     \n",
      "Ep 6 (Step 000045): Train loss 4.309, Val loss 6.218\n",
      "Ep 6 (Step 000050): Train loss 3.817, Val loss 6.161\n",
      "Every effort moves you know it's the                                              \n",
      "Ep 7 (Step 000055): Train loss 3.862, Val loss 6.207\n",
      "Ep 7 (Step 000060): Train loss 3.109, Val loss 6.113\n",
      "Every effort moves you know the fact that I was one of the Riv, I had the last word.                                 \n",
      "Ep 8 (Step 000065): Train loss 2.684, Val loss 6.105\n",
      "Ep 8 (Step 000070): Train loss 2.371, Val loss 6.141\n",
      "Every effort moves you know it was one of the picture--I had the fact with the last word.                                 \n",
      "Ep 9 (Step 000075): Train loss 1.991, Val loss 6.128\n",
      "Ep 9 (Step 000080): Train loss 1.638, Val loss 6.194\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on the last word.                                 \n",
      "Ep 10 (Step 000085): Train loss 1.330, Val loss 6.226\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that in a self-confident moustache, I had been re, and threw back the _not_ interesting--if I had the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11bff39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "  ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "  ax1.plot(\n",
    "  epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "  )\n",
    "  ax1.set_xlabel(\"Epochs\")\n",
    "  ax1.set_ylabel(\"Loss\")\n",
    "  ax1.legend(loc=\"upper right\")\n",
    "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "  ax2 = ax1.twiny()\n",
    "  ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "  ax2.set_xlabel(\"Tokens seen\")\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e922bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(123)\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.to(device)\n",
    "# optimizer = torch.optim.AdamW(\n",
    "#     model.parameters(),\n",
    "#     lr=0.0008, weight_decay=0.1\n",
    "# )\n",
    "# num_epochs = 25\n",
    "# train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "#     model, train_loader, val_loader, optimizer, device,\n",
    "#     num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "#     start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f91bb9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "#   fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "#   ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "#   ax1.plot(\n",
    "#   epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "#   )\n",
    "#   ax1.set_xlabel(\"Epochs\")\n",
    "#   ax1.set_ylabel(\"Loss\")\n",
    "#   ax1.legend(loc=\"upper right\")\n",
    "#   ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#   ax2 = ax1.twiny()\n",
    "#   ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "#   ax2.set_xlabel(\"Tokens seen\")\n",
    "#   fig.tight_layout()\n",
    "#   plt.show()\n",
    "# epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "# plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae1348",
   "metadata": {},
   "source": [
    "# **Decoding Strategies to Control Randomness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d116962b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bbc5adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that in a self-confident moustache, I\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Output text:\\n{token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937dada",
   "metadata": {},
   "source": [
    "### **Temperature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e942e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbfdba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e64d199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b10ddeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e552f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "              for i in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58ce0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "051958ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "                for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "        bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f0855",
   "metadata": {},
   "source": [
    "### **Top-k sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4660b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ffc1cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40e7269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1550b",
   "metadata": {},
   "source": [
    "### **Modifying the text generation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbd21deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_cond == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f67f00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves youlit to Gisburn rather a little to have my dear by his painting\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a9189",
   "metadata": {},
   "source": [
    "# **Loading and Saving Model Weights in PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "602b2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df8dc5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e07cad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ea4847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c277c1f",
   "metadata": {},
   "source": [
    "# **Loading pretrained weights fom OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "288c425d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x137130e10>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e53642d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vedantmisra/Developer/llm-from-scratch/.venv/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 90.8kiB/s]\n",
      "encoder.json: 100%|| 1.04M/1.04M [00:03<00:00, 286kiB/s] \n",
      "hparams.json: 100%|| 90.0/90.0 [00:00<00:00, 145kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|| 498M/498M [40:57<00:00, 203kiB/s]    \n",
      "model.ckpt.index: 100%|| 5.21k/5.21k [00:00<00:00, 3.19MiB/s]\n",
      "model.ckpt.meta: 100%|| 471k/471k [00:01<00:00, 296kiB/s]  \n",
      "vocab.bpe: 100%|| 456k/456k [00:03<00:00, 144kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c69e5431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Settings: {settings}\")\n",
    "print(f\"Parameter dictionary keys: {params.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d11f996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b41a8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "03cd2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae269ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "70f99ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d492014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                           \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a19e1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9812e8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5a03bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward more towards those more of harder steps in more actions easier ways in ways we to fewer those so instead more ways to more\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
