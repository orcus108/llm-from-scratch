# Chapter 1: Working with Text Data

## Main Chapter Code

- [01_main-code](01_main-code) contains the main chapter code.

## Bonus Materials

- [02_bytepair-encoder](02_bytepair-encoder) contains code to benchmark different implementations of the BPE algorithm (OpenAI's original, tiktoken, huggingface and my own).
- [03_embedding-vs-matmul](03_embedding-vs-matmul) contains code to explain that embedding layers and fully connected layers applied to one-hot encoded vectors are equivalent.
- [04_dataloader-intuition](04_dataloader-intuition) contains code to explain the data loader more intuitively with simple numbers rather than text.
- [05_bpe-from-scratch](05_bpe-from-scratch) contains code that implements and trains a GPT-2 BPE tokenizer from scratch [work in progress]